{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "column_names = [\"age\", \"workclass\", \"fnlwgt\", \"education\", \"education-num\", \"marital-status\", \"occupation\", \"relationship\", \"race\", \"sex\", \"capital-gain\", \"capital-loss\", \"hours-per-week\", \"native-country\", \"class\"]\n",
    "train_data = pd.read_csv(\"train.txt\", sep=\",\", header=None, names=column_names)\n",
    "test_data = pd.read_csv(\"test.txt\", sep=\",\", header=None, names=column_names[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age          workclass  fnlwgt   education  education-num  \\\n",
      "0   34            Private  287315     HS-grad              9   \n",
      "1   43        Federal-gov  145175   Bachelors             13   \n",
      "2   45          Local-gov   33798     Masters             14   \n",
      "3   23            Private  180497   Bachelors             13   \n",
      "4   65   Self-emp-not-inc  145628        10th              6   \n",
      "\n",
      "        marital-status          occupation    relationship    race      sex  \\\n",
      "0             Divorced   Machine-op-inspct   Not-in-family   White     Male   \n",
      "1   Married-civ-spouse        Adm-clerical         Husband   White     Male   \n",
      "2        Never-married      Prof-specialty   Not-in-family   White   Female   \n",
      "3        Never-married        Tech-support       Own-child   Black   Female   \n",
      "4   Married-civ-spouse        Craft-repair         Husband   White     Male   \n",
      "\n",
      "   capital-gain  capital-loss  hours-per-week  native-country   class  \n",
      "0             0             0              40   United-States   <=50K  \n",
      "1             0             0              42   United-States    >50K  \n",
      "2             0             0              40   United-States   <=50K  \n",
      "3             0             0              32   United-States   <=50K  \n",
      "4             0             0              40   United-States   <=50K  \n"
     ]
    }
   ],
   "source": [
    "print train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age          workclass  fnlwgt      education  education-num  \\\n",
      "0   36          Local-gov  126569   Some-college             10   \n",
      "1   26          State-gov   68346        Masters             14   \n",
      "2   58            Private  225394        HS-grad              9   \n",
      "3   60   Self-emp-not-inc   78913   Some-college             10   \n",
      "4   20            Private  218215   Some-college             10   \n",
      "\n",
      "        marital-status        occupation    relationship    race      sex  \\\n",
      "0   Married-civ-spouse   Protective-serv         Husband   White     Male   \n",
      "1        Never-married    Prof-specialty   Not-in-family   White     Male   \n",
      "2   Married-civ-spouse      Craft-repair         Husband   White     Male   \n",
      "3   Married-civ-spouse   Exec-managerial         Husband   White     Male   \n",
      "4        Never-married             Sales       Own-child   White   Female   \n",
      "\n",
      "   capital-gain  capital-loss  hours-per-week  native-country  \n",
      "0             0             0              40   United-States  \n",
      "1             0             0              10               ?  \n",
      "2             0          1902              40   United-States  \n",
      "3             0             0              50   United-States  \n",
      "4             0             0              30   United-States  \n"
     ]
    }
   ],
   "source": [
    "print test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age  fnlwgt  education-num  capital-gain  capital-loss  hours-per-week  \\\n",
      "0   34  287315              9             0             0              40   \n",
      "1   43  145175             13             0             0              42   \n",
      "2   45   33798             14             0             0              40   \n",
      "3   23  180497             13             0             0              32   \n",
      "4   65  145628              6             0             0              40   \n",
      "\n",
      "   label  \n",
      "0     -1  \n",
      "1      1  \n",
      "2     -1  \n",
      "3     -1  \n",
      "4     -1  \n",
      "        age    fnlwgt  education-num  capital-gain  capital-loss  \\\n",
      "0 -0.338110  0.920799      -0.420255     -0.144172      -0.21644   \n",
      "1  0.318397 -0.420698       1.138364     -0.144172      -0.21644   \n",
      "2  0.464288 -1.471858       1.528019     -0.144172      -0.21644   \n",
      "3 -1.140508 -0.087334       1.138364     -0.144172      -0.21644   \n",
      "4  1.923194 -0.416422      -1.589219     -0.144172      -0.21644   \n",
      "\n",
      "   hours-per-week  label  \n",
      "0       -0.033567     -1  \n",
      "1        0.128685      1  \n",
      "2       -0.033567     -1  \n",
      "3       -0.682575     -1  \n",
      "4       -0.033567     -1  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "# Compute mean of elements\n",
    "def mean(elements):\n",
    "    return float(sum(elements)) / float(len(elements))\n",
    "\n",
    "# Standard deviation mean of elements\n",
    "def standard_deviation(elements):\n",
    "    m = mean(elements)\n",
    "    var = sum([math.pow(e - m, 2) for e in elements]) / float(len(elements) - 1)\n",
    "    return math.sqrt(var)\n",
    "    \n",
    "def z_score_normalization(data):\n",
    "    for c in data.columns:\n",
    "        data[c] = (data[c] - data[c].mean()) / data[c].std(ddof=0)\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def cleaning(train_data, test_data):\n",
    "    drop_column = [\"workclass\", \"education\", \"marital-status\", \"occupation\", \"relationship\", \"race\", \"sex\", \"native-country\"]\n",
    "    train_data = train_data.drop(columns = drop_column)\n",
    "    test_data = test_data.drop(columns = drop_column)\n",
    "    train_data[\"label\"] = train_data[\"class\"].apply(lambda x: -1 if x == \" <=50K\" else 1)\n",
    "    train_data = train_data.drop(columns = \"class\")\n",
    "    print train_data.head()\n",
    "    return train_data, test_data\n",
    "\n",
    "train_data, X_test = cleaning(train_data, test_data)\n",
    "train_data.loc[:, train_data.columns != \"label\"] = z_score_normalization(train_data.loc[:, train_data.columns != \"label\"])\n",
    "X_test = z_score_normalization(X_test)\n",
    "print train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVM:\n",
    "    def __init__(self, v_len):\n",
    "        self.a = pd.DataFrame(np.random.uniform(size=v_len), \n",
    "                              index=[\"age\", \"fnlwgt\", \"education-num\", \"capital-gain\", \"capital-loss\", \"hours-per-week\"])\n",
    "        self.b = np.random.uniform()\n",
    "        self.l = 1e-3\n",
    "        \n",
    "    def fit(self, X_train, y_train, eta):\n",
    "        #a_n, b_n = self.a, self.b\n",
    "        a_n = pd.DataFrame(np.random.uniform(size=6), \n",
    "                              index=[\"age\", \"fnlwgt\", \"education-num\", \"capital-gain\", \"capital-loss\", \"hours-per-week\"])\n",
    "        b_n = np.random.uniform()\n",
    "        k = np.random.randint(len(y_train))\n",
    "        x_k, y_k = X_train.iloc[k], y_train.iloc[k]\n",
    "        for i in range(30):\n",
    "            if (y_k * (np.dot(a_n.T, x_k) + b_n)).item() >= 1:\n",
    "                a_n[0] = a_n[0] - eta * self.l * a_n[0]\n",
    "                b_n = b_n\n",
    "            else:\n",
    "                a_n[0] = a_n[0] - eta * (self.l * a_n[0] - y_k * x_k)\n",
    "                b_n = b_n + eta * y_k\n",
    "        self.a = a_n\n",
    "        self.b = b_n\n",
    "    \n",
    "    def predict(self, x):\n",
    "        return 1 if (np.dot(self.a.T, x) + self.b).item() >= 0 else -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# + reshuflle + without replacement \n",
    "def train_val_split(data, size):\n",
    "    train_data, val_data = np.split(data.sample(frac=1, replace=False), [size])\n",
    "    X_train, y_train = np.split(train_data, [-1], axis=1)\n",
    "    X_val, y_val = np.split(val_data, [-1], axis=1)\n",
    "    y_train = np.squeeze(y_train) # for n x 1 vector\n",
    "    y_val = np.squeeze(y_val) # for n x 1 vector\n",
    "    return X_train, y_train, X_val, y_val\n",
    "\n",
    "def compute_accuracy(svm, X_val, y_val, l):\n",
    "    accuracy = 0\n",
    "    for i, x in X_val.iterrows():\n",
    "        if svm.predict(x) == y_val[i]:\n",
    "            accuracy += 1\n",
    "    accuracy /= float(len(X_val))\n",
    "    #print \"Accuracy is \" + str(accuracy) + \" with lamdba = \" + str(l)\n",
    "    return accuracy\n",
    "\n",
    "def output_for_autograder(svm, X_test):\n",
    "    with open(\"submission.txt\", \"w\") as test_file:\n",
    "        for i, x in X_test.iterrows():\n",
    "            if svm.predict(x) == -1:\n",
    "                test_file.write(\"<=50K\\n\")\n",
    "            else:\n",
    "                test_file.write(\">50K\\n\")\n",
    "\n",
    "def cross_validation(svm, train_data):\n",
    "    max_accuracy_lambda = 0\n",
    "    best_parameters = (0, 0)\n",
    "    for l in [1e-3, 1e-2, 1e-1, 1]: # find best lambda hyperparameter\n",
    "        X_train_lamdba, y_train_lamdba, X_val_lamdba, y_val_lamdba = train_val_split(train_data, int(.9*len(train_data)))\n",
    "        svm.l = l\n",
    "        max_accuracy_eta, best_eta = 0, 0\n",
    "        n_season = 100 # Number of season at least 50\n",
    "        for season in range(n_season):\n",
    "            eta = 10 / float(season + 50) #  acc(20)=0.77\n",
    "            #eta = 10 / float(season + 200)\n",
    "            train_val_eta = pd.concat([X_train_lamdba, y_train_lamdba], axis=1)\n",
    "            season_size = 300 # Size of season at least 300 try with 600\n",
    "            while season_size >= 30:\n",
    "                X_train_eta, y_train_eta, X_val_eta, y_val_eta = train_val_split(train_val_eta.sample(n=season_size), season_size-50)\n",
    "                svm.fit(X_train_eta, y_train_eta, eta) \n",
    "                accuracy_eta = compute_accuracy(svm, X_val_eta, y_val_eta, l)\n",
    "                if accuracy_eta > max_accuracy_eta:\n",
    "                    max_accuracy_eta = accuracy_eta\n",
    "                    best_eta = eta\n",
    "                season_size -= 30\n",
    "                # plot magnitude of the coefficient vector every 30 steps, for each value of the regularization constant.\n",
    "                # plot held out accuracy every 30 steps, for each value of the regularization constant.\n",
    "        svm.fit(X_train_lamdba, y_train_lamdba, best_eta)\n",
    "        accuracy_lambda = compute_accuracy(svm, X_val_lamdba, y_val_lamdba, l)\n",
    "        if accuracy_lambda > max_accuracy_lambda:\n",
    "                max_accuracy_lambda = accuracy_lambda\n",
    "                best_parameters = (l, best_eta)\n",
    "    print \"Max accuracy is \" + str(max_accuracy_lambda)\n",
    "    print \"Best parameters is \" + str(best_parameters)\n",
    "    return best_parameters\n",
    "\n",
    "x_len = 6\n",
    "svm = SVM(x_len)\n",
    "svm.l, eta = cross_validation(svm, train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = np.split(train_data, [-1], axis=1)\n",
    "svm.fit(X_train, y_train, eta)\n",
    "output_for_autograder(svm, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
