{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "column_names = [\"age\", \"workclass\", \"fnlwgt\", \"education\", \"education-num\", \"marital-status\", \"occupation\", \"relationship\", \"race\", \"sex\", \"capital-gain\", \"capital-loss\", \"hours-per-week\", \"native-country\", \"class\"]\n",
    "train_data = pd.read_csv(\"train.txt\", sep=\",\", header=None, names=column_names)\n",
    "test_data = pd.read_csv(\"test.txt\", sep=\",\", header=None, names=column_names[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age          workclass  fnlwgt   education  education-num  \\\n",
      "0   34            Private  287315     HS-grad              9   \n",
      "1   43        Federal-gov  145175   Bachelors             13   \n",
      "2   45          Local-gov   33798     Masters             14   \n",
      "3   23            Private  180497   Bachelors             13   \n",
      "4   65   Self-emp-not-inc  145628        10th              6   \n",
      "\n",
      "        marital-status          occupation    relationship    race      sex  \\\n",
      "0             Divorced   Machine-op-inspct   Not-in-family   White     Male   \n",
      "1   Married-civ-spouse        Adm-clerical         Husband   White     Male   \n",
      "2        Never-married      Prof-specialty   Not-in-family   White   Female   \n",
      "3        Never-married        Tech-support       Own-child   Black   Female   \n",
      "4   Married-civ-spouse        Craft-repair         Husband   White     Male   \n",
      "\n",
      "   capital-gain  capital-loss  hours-per-week  native-country   class  \n",
      "0             0             0              40   United-States   <=50K  \n",
      "1             0             0              42   United-States    >50K  \n",
      "2             0             0              40   United-States   <=50K  \n",
      "3             0             0              32   United-States   <=50K  \n",
      "4             0             0              40   United-States   <=50K  \n"
     ]
    }
   ],
   "source": [
    "print train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age          workclass  fnlwgt      education  education-num  \\\n",
      "0   36          Local-gov  126569   Some-college             10   \n",
      "1   26          State-gov   68346        Masters             14   \n",
      "2   58            Private  225394        HS-grad              9   \n",
      "3   60   Self-emp-not-inc   78913   Some-college             10   \n",
      "4   20            Private  218215   Some-college             10   \n",
      "\n",
      "        marital-status        occupation    relationship    race      sex  \\\n",
      "0   Married-civ-spouse   Protective-serv         Husband   White     Male   \n",
      "1        Never-married    Prof-specialty   Not-in-family   White     Male   \n",
      "2   Married-civ-spouse      Craft-repair         Husband   White     Male   \n",
      "3   Married-civ-spouse   Exec-managerial         Husband   White     Male   \n",
      "4        Never-married             Sales       Own-child   White   Female   \n",
      "\n",
      "   capital-gain  capital-loss  hours-per-week  native-country  \n",
      "0             0             0              40   United-States  \n",
      "1             0             0              10               ?  \n",
      "2             0          1902              40   United-States  \n",
      "3             0             0              50   United-States  \n",
      "4             0             0              30   United-States  \n"
     ]
    }
   ],
   "source": [
    "print test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age  fnlwgt  education-num  capital-gain  capital-loss  hours-per-week  \\\n",
      "0   34  287315              9             0             0              40   \n",
      "1   43  145175             13             0             0              42   \n",
      "2   45   33798             14             0             0              40   \n",
      "3   23  180497             13             0             0              32   \n",
      "4   65  145628              6             0             0              40   \n",
      "\n",
      "   label  \n",
      "0     -1  \n",
      "1      1  \n",
      "2     -1  \n",
      "3     -1  \n",
      "4     -1  \n",
      "        age    fnlwgt  education-num  capital-gain  capital-loss  \\\n",
      "0 -0.338110  0.920799      -0.420255     -0.144172      -0.21644   \n",
      "1  0.318397 -0.420698       1.138364     -0.144172      -0.21644   \n",
      "2  0.464288 -1.471858       1.528019     -0.144172      -0.21644   \n",
      "3 -1.140508 -0.087334       1.138364     -0.144172      -0.21644   \n",
      "4  1.923194 -0.416422      -1.589219     -0.144172      -0.21644   \n",
      "\n",
      "   hours-per-week  label  \n",
      "0       -0.033567     -1  \n",
      "1        0.128685      1  \n",
      "2       -0.033567     -1  \n",
      "3       -0.682575     -1  \n",
      "4       -0.033567     -1  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "# Compute mean of elements\n",
    "def mean(elements):\n",
    "    return float(sum(elements)) / float(len(elements))\n",
    "\n",
    "# Standard deviation mean of elements\n",
    "def standard_deviation(elements):\n",
    "    m = mean(elements)\n",
    "    var = sum([math.pow(e - m, 2) for e in elements]) / float(len(elements) - 1)\n",
    "    return math.sqrt(var)\n",
    "    \n",
    "def z_score_normalization(data):\n",
    "    for c in data.columns:\n",
    "        data[c] = (data[c] - data[c].mean()) / data[c].std(ddof=0)\n",
    "    return data\n",
    "\n",
    "def cleaning(train_data, test_data):\n",
    "    drop_column = [\"workclass\", \"education\", \"marital-status\", \"occupation\", \"relationship\", \"race\", \"sex\", \"native-country\"]\n",
    "    train_data = train_data.drop(columns = drop_column)\n",
    "    test_data = test_data.drop(columns = drop_column)\n",
    "    train_data[\"label\"] = train_data[\"class\"].apply(lambda x: -1 if x == \" <=50K\" else 1)\n",
    "    train_data = train_data.drop(columns = \"class\")\n",
    "    print train_data.head()\n",
    "    return train_data, test_data\n",
    "\n",
    "train_data, X_test = cleaning(train_data, test_data)\n",
    "train_data.loc[:, train_data.columns != \"label\"] = z_score_normalization(train_data.loc[:, train_data.columns != \"label\"])\n",
    "X_test = z_score_normalization(X_test)\n",
    "print train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.int64' object has no attribute 'to_frame'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-222-294ab8d1b523>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0;31m#split data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0;31m#do cross_validation to find the best step size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-222-294ab8d1b523>\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(train_data)\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mtrain_val_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_train_lamdba\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_lamdba\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0mX_val_stepsize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val_stepsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_val_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_SVM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m             \u001b[0;31m#split data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0;31m#do cross_validation to find the best step size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-222-294ab8d1b523>\u001b[0m in \u001b[0;36mtrain_SVM\u001b[0;34m(X_train, y_train, l)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mx_k\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0my_k\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_k\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.int64' object has no attribute 'to_frame'"
     ]
    }
   ],
   "source": [
    "def train_val_split(data):\n",
    "    train_data, val_data = np.split(data.sample(frac=1), [int(.9*len(data))])\n",
    "    X_train, y_train = np.split(train_data, [-1], axis=1)\n",
    "    X_val, y_val = np.split(test_data, [-1], axis=1)\n",
    "    y_train = np.squeeze(y_train) # for n x 1 vector\n",
    "    y_val = np.squeeze(y_val) # for n x 1 vector\n",
    "    return X_train, y_train, X_val, y_val\n",
    "\n",
    "\n",
    "#def gradient_descent(l, step_size, x_k, y_k, n_steps): ################### Verify!!!!!\n",
    "#    a = pd.DataFrame(np.random.randint(1, len(x_k)))\n",
    "#    b = pd.random.randint(1)\n",
    "#    a_prev, b_prev = a, b\n",
    "#    a_next, b_next = [0] * len(x), 0\n",
    " #   n_steps = 300\n",
    "  #  for i in range(n_steps):\n",
    "   #     if y_k * (a.T.dot(x_k) + b) >= 1:\n",
    "    #        a_next = a_prev -  step_size * a.apply(lambda x: x * l)\n",
    "     #       b_next = b_prev\n",
    "      #  else:\n",
    "       #     a_next = a_prev -  step_size * (a.apply(lambda x: x * l) - y_k * x_k)\n",
    "        #    b_next = b_prev + step_size * y_k\n",
    " #   return a_next, b_next\n",
    "\n",
    "def train_SVM(X_train, y_train, l):\n",
    "    step_size = 1\n",
    "    a = pd.DataFrame(np.random.rand(1, len(X_train.iloc[0])))\n",
    "    b = np.random.randint(1)\n",
    "    a_prev, b_prev = a, b\n",
    "    a_next, b_next = pd.DataFrame([0] * len(X_train.iloc[0])), 0\n",
    "    k = np.random.randint(len(y_train))\n",
    "    x_k = X_train.iloc[k]\n",
    "    y_k = y_train.iloc[k]\n",
    "    print type(x_k)\n",
    "    print type(a)\n",
    "    for i in range(300):\n",
    "        if y_k * (a.T.dot(x_k) + b) >= 1:\n",
    "            a_next = a_prev -  step_size * a.apply(lambda x: x * l)\n",
    "            b_next = b_prev\n",
    "        else:\n",
    "            a_next = a_prev -  step_size * (a.apply(lambda x: x * l) - y_k * x_k)\n",
    "            b_next = b_prev + step_size * y_k\n",
    "    return a_next, b_next\n",
    "\n",
    "def cross_validation(train_data):\n",
    "    # compute eta first\n",
    "    \n",
    "    for l in [1e-3, 1e-2, 1e-1, 1]: # find bestlamdba hyperparameter\n",
    "        X_train_lamdba, y_train_lamdba, X_val_lamdba, y_val_lamdba = train_val_split(train_data)\n",
    "        for epoch in range(50): # Number of epochs => TBD\n",
    "            train_val_data = pd.concat([X_train_lamdba, y_train_lamdba], axis=1)\n",
    "            X_val_stepsize, y_val_stepsize = np.split(train_val_data.sample(n=50), [-1], axis=1)\n",
    "            a, b = train_SVM(X_train, y_train, l)\n",
    "            #split data\n",
    "            #do cross_validation to find the best step size\n",
    "cross_validation(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
